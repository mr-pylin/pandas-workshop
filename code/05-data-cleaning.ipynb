{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1f7a74ec",
      "metadata": {},
      "source": [
        "<div style=\"display: flex; justify-content: space-between; align-items: center;\">\n",
        "    <div style=\"text-align: left; flex: 4\">\n",
        "        <strong>Author:</strong> Amirhossein Heydari ‚Äî \n",
        "        üìß <a href=\"mailto:amirhosseinheydari78@gmail.com\">amirhosseinheydari78@gmail.com</a> ‚Äî \n",
        "        üêô <a href=\"https://github.com/mr-pylin/pandas-workshop\" target=\"_blank\" rel=\"noopener\">github.com/mr-pylin</a>\n",
        "    </div>\n",
        "    <div style=\"text-align: right; flex: 1;\">\n",
        "        <a href=\"https://pandas.pydata.org/\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
        "            <img src=\"../assets/images/pandas/logo/pandas_white.svg\" \n",
        "                 alt=\"Pandas Logo\"\n",
        "                 style=\"max-height: 48px; width: auto; background-color: #1f1f1f; border-radius: 8px;\">\n",
        "        </a>\n",
        "    </div>\n",
        "</div>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfbcc943",
      "metadata": {},
      "source": [
        "**Table of contents**<a id='toc0_'></a>    \n",
        "- [Dependencies](#toc1_)    \n",
        "- [Load Titanic Dataset](#toc2_)    \n",
        "- [Data Cleaning and Transformation](#toc3_)    \n",
        "  - [Handling Missing Data](#toc3_1_)    \n",
        "    - [Detecting Missing Values](#toc3_1_1_)    \n",
        "    - [Dropping Missing Data](#toc3_1_2_)    \n",
        "    - [Filling Missing Data](#toc3_1_3_)    \n",
        "    - [Interpolate Missing Values](#toc3_1_4_)    \n",
        "    - [Replacing Specific Values](#toc3_1_5_)    \n",
        "  - [Duplicates and Unique Values](#toc3_2_)    \n",
        "    - [Finding Duplicates](#toc3_2_1_)    \n",
        "    - [Removing Duplicates](#toc3_2_2_)    \n",
        "    - [Getting Unique Values](#toc3_2_3_)    \n",
        "    - [Counting Unique Values](#toc3_2_4_)    \n",
        "  - [String Operations](#toc3_3_)    \n",
        "    - [Accessing String Methods](#toc3_3_1_)    \n",
        "    - [Pattern Matching with Regex](#toc3_3_2_)    \n",
        "    - [Extracting or Splitting Strings](#toc3_3_3_)    \n",
        "  - [Type Conversions and Categoricals](#toc3_4_)    \n",
        "    - [Converting Column Types](#toc3_4_1_)    \n",
        "    - [Handling Mixed Types](#toc3_4_2_)    \n",
        "    - [Working with Categorical Data](#toc3_4_3_)    \n",
        "    - [Optimizing Memory with Categoricals](#toc3_4_4_)    \n",
        "  - [Renaming Columns and Indexes](#toc3_5_)    \n",
        "    - [Renaming Columns](#toc3_5_1_)    \n",
        "    - [Renaming Index or Index Levels](#toc3_5_2_)    \n",
        "\n",
        "<!-- vscode-jupyter-toc-config\n",
        "\tnumbering=false\n",
        "\tanchor=true\n",
        "\tflat=false\n",
        "\tminLevel=1\n",
        "\tmaxLevel=6\n",
        "\t/vscode-jupyter-toc-config -->\n",
        "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e73df675",
      "metadata": {},
      "source": [
        "# <a id='toc1_'></a>[Dependencies](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32ec40e5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0a55812",
      "metadata": {},
      "outputs": [],
      "source": [
        "# disable wrapping entirely\n",
        "pd.set_option(\"display.expand_frame_repr\", False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "849871b7",
      "metadata": {},
      "source": [
        "# <a id='toc2_'></a>[Load Titanic Dataset](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2669dc79",
      "metadata": {},
      "outputs": [],
      "source": [
        "TITANIC_PATH = (\n",
        "    r\"https://raw.githubusercontent.com/mr-pylin/datasets/refs/heads/main/data/tabular-data/titanic/train.csv\"\n",
        ")\n",
        "df = pd.read_csv(TITANIC_PATH, encoding=\"UTF8\").drop(columns=[\"Cabin\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68b5dd55",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68a2a53b",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7e68c14",
      "metadata": {},
      "source": [
        "# <a id='toc3_'></a>[Data Cleaning and Transformation](#toc0_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2aec73f",
      "metadata": {},
      "source": [
        "## <a id='toc3_1_'></a>[Handling Missing Data](#toc0_)\n",
        "\n",
        "- Real-world datasets often contain **missing**, **null**, or **undefined** values.\n",
        "- In Pandas, missing data is usually represented by **`NaN` (Not a Number)** or **`None`** for object types.\n",
        "- Properly handling missing data is essential for **data integrity**, **analysis accuracy**, and **model performance**.\n",
        "- Pandas provides several built-in tools for **detecting**, **removing**, **filling**, and **interpolating** missing values.\n",
        "\n",
        "‚úçÔ∏è **Key Concepts**\n",
        "\n",
        "- **Detection:** Identify missing entries using `.isna()` or `.notna()`.\n",
        "- **Removal:** Drop missing rows or columns with `.dropna()`.\n",
        "- **Imputation:** Fill missing values with constants or computed statistics using `.fillna()`.\n",
        "- **Interpolation:** Estimate missing numeric data based on trends with `.interpolate()`.\n",
        "- **Replacement:** Replace specific placeholders (e.g., `\"N/A\"`, `\"-\"`) with `NaN` or valid values.\n",
        "\n",
        "üìù **Docs**:\n",
        "- `DataFrame.isna()`: [pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html)\n",
        "- `DataFrame.dropna()`: [pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html)\n",
        "- `DataFrame.fillna()`: [pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html)\n",
        "- `DataFrame.interpolate()`: [pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html)\n",
        "- `DataFrame.replace()`: [pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10ac93d5",
      "metadata": {},
      "source": [
        "### <a id='toc3_1_1_'></a>[Detecting Missing Values](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce73653d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# check for missing values in each column\n",
        "df.isna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60f18915",
      "metadata": {},
      "outputs": [],
      "source": [
        "# summarize missing values per column\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af5fad87",
      "metadata": {},
      "outputs": [],
      "source": [
        "# check if any missing values exist in the entire DataFrame\n",
        "df.isna().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c629d82",
      "metadata": {},
      "outputs": [],
      "source": [
        "# show rows that contain any missing values\n",
        "df[df.isna().any(axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ce3f022",
      "metadata": {},
      "outputs": [],
      "source": [
        "# show rows missing a specific column\n",
        "df[df[\"Embarked\"].isna()]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04f358f8",
      "metadata": {},
      "source": [
        "### <a id='toc3_1_2_'></a>[Dropping Missing Data](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c67c8bc1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# drop rows that have any missing value\n",
        "df_drop_rows = df.dropna()\n",
        "\n",
        "# log\n",
        "print(f\"df_drop_rows.shape: {df_drop_rows.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97c6346a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# drop columns that have any missing value\n",
        "df_drop_columns = df.dropna(axis=1)\n",
        "\n",
        "# log\n",
        "print(f\"df_drop_columns.shape: {df_drop_columns.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1b4f2c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# drop rows where a specific column is missing\n",
        "df_drop_embarked = df.dropna(subset=[\"Embarked\"])\n",
        "\n",
        "# log\n",
        "print(f\"df_drop_embarked.shape: {df_drop_embarked.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b987bb6f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# keep rows with at least a certain number of non-missing values\n",
        "df_drop_thresh = df.dropna(thresh=10)\n",
        "\n",
        "# log\n",
        "print(f\"df_drop_thresh.shape: {df_drop_thresh.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "866d7da9",
      "metadata": {},
      "source": [
        "### <a id='toc3_1_3_'></a>[Filling Missing Data](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "365034a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# fill missing values with a constant\n",
        "df_fill_constant = df.fillna(0)\n",
        "\n",
        "# log\n",
        "df_fill_constant[df[[\"Age\", \"Embarked\"]].isna().any(axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2fbca80",
      "metadata": {},
      "outputs": [],
      "source": [
        "# fill missing values in a specific column\n",
        "df_fill_age = df.copy()\n",
        "df_fill_age[\"Age\"] = df[\"Age\"].fillna(99)\n",
        "\n",
        "# log\n",
        "df_fill_age[df[\"Age\"].isna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfb18a56",
      "metadata": {},
      "outputs": [],
      "source": [
        "# fill missing values with column mean, median, or mode\n",
        "df[\"Age\"].fillna(df[\"Age\"].mean())\n",
        "df[\"Age\"].fillna(df[\"Age\"].median())\n",
        "df[\"Embarked\"].fillna(df[\"Embarked\"].mode()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9a3d611",
      "metadata": {},
      "outputs": [],
      "source": [
        "# forward-fill and backward-fill (propagate nearby values)\n",
        "df_ffill = df.ffill()\n",
        "df_bfill = df.bfill()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b92177b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# fill using a dictionary for **column-specific values**\n",
        "df.fillna({\"Age\": df[\"Age\"].median(), \"Embarked\": \"S\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1261dcbd",
      "metadata": {},
      "source": [
        "### <a id='toc3_1_4_'></a>[Interpolate Missing Values](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3273b837",
      "metadata": {},
      "outputs": [],
      "source": [
        "# simple linear interpolation for numeric columns\n",
        "age_1 = df[\"Age\"].interpolate(method=\"linear\")\n",
        "\n",
        "# log\n",
        "age_1.iloc[26:32]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f061ad9b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# interpolation using non-linear methods\n",
        "age_2 = df['Age'].interpolate(method='polynomial', order=2)\n",
        "\n",
        "# log\n",
        "age_2.iloc[26:32]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "554f3f65",
      "metadata": {},
      "outputs": [],
      "source": [
        "# limit the number of consecutive NaNs to fill\n",
        "age_3 = df[\"Age\"].interpolate(limit=1)\n",
        "\n",
        "# log\n",
        "age_3.iloc[26:32]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "639e7554",
      "metadata": {},
      "outputs": [],
      "source": [
        "# directional interpolation\n",
        "age_4 = df[\"Age\"].interpolate(method=\"linear\", limit_direction=\"backward\", limit=1)\n",
        "\n",
        "# log\n",
        "age_4.iloc[26:32]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c63f7db1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# apply interpolation to a dataframe\n",
        "age_5 = df.select_dtypes(include='number').interpolate(method='linear')\n",
        "\n",
        "# log\n",
        "age_5.iloc[26:32]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13f988bb",
      "metadata": {},
      "source": [
        "### <a id='toc3_1_5_'></a>[Replacing Specific Values](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f1fb0e5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# replace a single value\n",
        "df['Embarked'].replace('S', 'Southampton')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "958ebbd6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# replace multiple values at once\n",
        "df['Embarked'].replace({'C': 'Cherbourg', 'Q': 'Queenstown'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6be1754",
      "metadata": {},
      "outputs": [],
      "source": [
        "# replace numeric values\n",
        "df.replace({'Pclass': {1: 'First', 2: 'Second', 3: 'Third'}})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4204eb1f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# replace using a list\n",
        "df.replace([np.float64('nan'), 'N/A'], 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f93b949c",
      "metadata": {},
      "source": [
        "## <a id='toc3_2_'></a>[Duplicates and Unique Values](#toc0_)\n",
        "\n",
        "- Real-world datasets often contain **duplicate records** or **repeated values** due to merging errors, manual entries, or data collection issues.\n",
        "- Detecting and removing duplicates is an essential step in **data cleaning**, ensuring accurate **aggregations**, **statistics**, and **model training**.\n",
        "- Pandas provides intuitive methods to identify, count, and drop duplicate rows or values.\n",
        "- Similarly, finding **unique values** helps understand **data variability** and is often used in **categorical feature analysis**.\n",
        "\n",
        "‚úçÔ∏è **Key Concepts**\n",
        "\n",
        "- **Detect duplicates:** Use `.duplicated()` to check whether a row (or specific subset of columns) is a duplicate.\n",
        "- **Remove duplicates:** Use `.drop_duplicates()` to remove duplicate rows, optionally keeping the first or last occurrence.\n",
        "- **Find unique values:** Use `.unique()` for one-dimensional Series or `.nunique()` to count distinct values.\n",
        "- **Subset selection:** Both `.duplicated()` and `.drop_duplicates()` support the `subset` argument to consider specific columns only.\n",
        "\n",
        "üí° **Example scenarios:**\n",
        "- Identifying users who appear multiple times in a transaction log.\n",
        "- Cleaning a dataset after concatenating multiple CSVs.\n",
        "- Counting how many unique categories or product IDs exist.\n",
        "\n",
        "üìù **Docs**:\n",
        "- `DataFrame.duplicated()`: [pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html)\n",
        "- `DataFrame.drop_duplicates()`: [pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html)\n",
        "- `Series.unique()`: [pandas.pydata.org/docs/reference/api/pandas.Series.unique.html](https://pandas.pydata.org/docs/reference/api/pandas.Series.unique.html)\n",
        "- `Series.nunique()`: [pandas.pydata.org/docs/reference/api/pandas.Series.nunique.html](https://pandas.pydata.org/docs/reference/api/pandas.Series.nunique.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d2430c5",
      "metadata": {},
      "source": [
        "### <a id='toc3_2_1_'></a>[Finding Duplicates](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45fc9ddb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# check for duplicate rows in the DataFrame\n",
        "df.duplicated()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e048a1f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# find duplicates based on specific column(s)\n",
        "df[df.duplicated(subset=['Survived', 'Pclass', 'Age', 'Sex', 'Embarked'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32d0b5a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# find all duplicates based on specific column(s)\n",
        "df[df.duplicated(subset=['Survived', 'Pclass', 'Age', 'Sex', 'Embarked'], keep=False)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62b6eca4",
      "metadata": {},
      "source": [
        "### <a id='toc3_2_2_'></a>[Removing Duplicates](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d2cccef",
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove duplicate rows based on all columns\n",
        "df.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48d3015c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove duplicates based on specific column(s)\n",
        "df.drop_duplicates(subset=['Survived', 'Pclass', 'Age', 'Sex', 'Embarked'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be940bd1",
      "metadata": {},
      "source": [
        "### <a id='toc3_2_3_'></a>[Getting Unique Values](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5927d056",
      "metadata": {},
      "outputs": [],
      "source": [
        "# get unique values in a column\n",
        "df['Pclass'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6daa957c",
      "metadata": {},
      "source": [
        "### <a id='toc3_2_4_'></a>[Counting Unique Values](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20d78207",
      "metadata": {},
      "outputs": [],
      "source": [
        "# count unique values across all columns\n",
        "df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24944c44",
      "metadata": {},
      "outputs": [],
      "source": [
        "# count number of unique values in a column\n",
        "df['Age'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71fa58bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# count occurrences of each unique value\n",
        "df['Survived'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f945048",
      "metadata": {},
      "outputs": [],
      "source": [
        "# include NaN in counts\n",
        "df['Age'].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "247e3e75",
      "metadata": {},
      "source": [
        "## <a id='toc3_3_'></a>[String Operations](#toc0_)\n",
        "\n",
        "- Text data is common in datasets ‚Äî such as names, categories, emails, or addresses ‚Äî and Pandas provides powerful **vectorized string operations** through the `.str` accessor.\n",
        "- These methods allow you to manipulate and clean textual data **efficiently**, without using loops.\n",
        "- Common tasks include **case conversion**, **trimming whitespace**, **extracting substrings**, **pattern matching**, and **regular expression** operations.\n",
        "\n",
        "‚úçÔ∏è **Key Concepts**\n",
        "\n",
        "- **Access string methods:** Use `.str.<method>` to apply string functions element-wise on a Series or Index.\n",
        "- **Case operations:** Convert text to lowercase, uppercase, or title case using `.str.lower()`, `.str.upper()`, `.str.title()`.\n",
        "- **Whitespace handling:** Remove or strip unwanted spaces with `.str.strip()`, `.str.lstrip()`, `.str.rstrip()`.\n",
        "- **Splitting and joining:** Split text into lists with `.str.split()` or join elements using `.str.join()`.\n",
        "- **Substring extraction:** Use `.str.slice()` or `.str.extract()` (with regex) for substring selection.\n",
        "- **Containment and replacement:** Check for patterns using `.str.contains()` and replace text via `.str.replace()`.\n",
        "- **Regex support:** Most `.str` methods support powerful pattern matching through regular expressions.\n",
        "\n",
        "üí° **Example scenarios:**\n",
        "- Cleaning inconsistent capitalization in names.\n",
        "- Extracting domains from email addresses.\n",
        "- Detecting product codes or IDs in unstructured text.\n",
        "- Normalizing whitespace and removing special symbols.\n",
        "\n",
        "üìù **Docs**:\n",
        "- `Series.str`: [pandas.pydata.org/docs/reference/api/pandas.Series.str.html](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.html)\n",
        "- `Series.str.contains()`: [pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html)\n",
        "- `Series.str.replace()`: [pandas.pydata.org/docs/reference/api/pandas.Series.str.replace.html](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.replace.html)\n",
        "- `Series.str.extract()`: [pandas.pydata.org/docs/reference/api/pandas.Series.str.extract.html](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extract.html)\n",
        "- `Series.str.split()`: [pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7bee552",
      "metadata": {},
      "source": [
        "### <a id='toc3_3_1_'></a>[Accessing String Methods](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12f06f0a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert to lowercase\n",
        "df['Name'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "289b447e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert to uppercase\n",
        "df['Name'].str.upper()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb4e1900",
      "metadata": {},
      "outputs": [],
      "source": [
        "# get length of each string\n",
        "df['Name'].str.len()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3827b914",
      "metadata": {},
      "outputs": [],
      "source": [
        "# check if string contains a substring\n",
        "df['Name'].str.contains('Mr.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a53b629d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# access first n characters\n",
        "df['Name'].str[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e3433b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# strip leading/trailing whitespace\n",
        "df['Name'].str.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "135842b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# replace substrings\n",
        "df[\"Name\"].str.replace('Mr.', 'Mister')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5877a47",
      "metadata": {},
      "outputs": [],
      "source": [
        "# concatenate strings with another Series or string\n",
        "titles = df['Name'].str.extract(r'(\\w+)\\.')\n",
        "df[\"Name\"] + ' (' + titles[0] + ')'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f211433",
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove punctuation or unwanted characters using regex\n",
        "df[\"Name\"].str.replace(r'[^\\w\\s]', '', regex=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05527993",
      "metadata": {},
      "source": [
        "### <a id='toc3_3_2_'></a>[Pattern Matching with Regex](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96e23ed3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# check if a pattern exists in each string\n",
        "df['Name'].str.contains(r'Mr\\.', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e57d7cf0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# extract a pattern using capturing groups\n",
        "df['Name'].str.extract(r'(\\w+)\\.')  # Captures 'Mr', 'Mrs', etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5aa27dfc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# replace patterns\n",
        "df['Name'].str.replace(r'Mr\\.|Mrs\\.', 'Title', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5ffada5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# find all occurrences of a pattern\n",
        "df['Name'].str.findall(r'\\b\\w+\\b')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47503533",
      "metadata": {},
      "outputs": [],
      "source": [
        "# match exact pattern (boolean)\n",
        "df['Name'].str.match(r'.*Master\\..*')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5f11f54",
      "metadata": {},
      "source": [
        "### <a id='toc3_3_3_'></a>[Extracting or Splitting Strings](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e862066",
      "metadata": {},
      "outputs": [],
      "source": [
        "# split strings by a delimiter\n",
        "df['Name'].str.split(',', expand=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbf867b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# split first/last names\n",
        "df['Name'].str.split(' ', n=1, expand=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d34ed005",
      "metadata": {},
      "outputs": [],
      "source": [
        "# get first element after split\n",
        "df['Name'].str.split(' ', expand=True)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb7af3fa",
      "metadata": {},
      "outputs": [],
      "source": [
        "# example of multiple captures in regex\n",
        "df['Name'].str.extract(r'(?P<LastName>\\w+),\\s(?P<Title>\\w+)\\.\\s(?P<FirstName>.*)')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "314f4ea7",
      "metadata": {},
      "source": [
        "## <a id='toc3_4_'></a>[Type Conversions and Categoricals](#toc0_)\n",
        "\n",
        "- Ensuring that each column in your dataset has the **correct data type** (`dtype`) is critical for accurate analysis and efficient memory usage.\n",
        "- Pandas supports **automatic type inference**, but manual type conversion is often required ‚Äî for example, converting strings to numbers or dates.\n",
        "- Additionally, **categorical data** offers a memory-efficient way to represent repeated string labels and is useful for modeling and grouping operations.\n",
        "\n",
        "‚úçÔ∏è **Key Concepts**\n",
        "\n",
        "- **Check dtypes:** Use `.dtypes` or `.info()` to inspect column data types.\n",
        "- **Convert types:** Use `.astype()` to cast a Series or entire DataFrame to a different dtype (e.g., `int`, `float`, `str`, `bool`).\n",
        "- **Numeric conversion:** Use `pd.to_numeric()` to safely convert strings to numbers, coercing invalid values to `NaN`.\n",
        "- **Datetime conversion:** Use `pd.to_datetime()` for parsing strings into proper datetime objects.\n",
        "- **Categorical conversion:** Convert string columns with limited unique values to `category` dtype for performance and memory efficiency.\n",
        "- **Categorical ordering:** Use `CategoricalDtype` to specify custom category orderings for sorting or comparisons.\n",
        "\n",
        "üí° **Benefits of Categoricals:**\n",
        "- Reduced memory footprint for columns with few unique values.\n",
        "- Faster groupby and comparison operations.\n",
        "- Allows explicit ordering (e.g., `low < medium < high`).\n",
        "\n",
        "üìù **Docs**:\n",
        "- `DataFrame.astype()`: [pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html)\n",
        "- `pandas.to_numeric()`: [pandas.pydata.org/docs/reference/api/pandas.to_numeric.html](https://pandas.pydata.org/docs/reference/api/pandas.to_numeric.html)\n",
        "- `pandas.to_datetime()`: [pandas.pydata.org/docs/reference/api/pandas.to_datetime.html](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html)\n",
        "- `CategoricalDtype`: [pandas.pydata.org/docs/reference/api/pandas.api.types.CategoricalDtype.html](https://pandas.pydata.org/docs/reference/api/pandas.api.types.CategoricalDtype.html)\n",
        "- `Categorical`: [pandas.pydata.org/docs/reference/api/pandas.Categorical.html](https://pandas.pydata.org/docs/reference/api/pandas.Categorical.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff0b1aca",
      "metadata": {},
      "source": [
        "### <a id='toc3_4_1_'></a>[Converting Column Types](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c80a529",
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert 'Pclass' from int64 to string\n",
        "df[\"Pclass\"].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3366a991",
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert 'Fare' to float (if not already)\n",
        "df[\"Fare\"].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f6acd1c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert 'Survived' to boolean\n",
        "df[\"Survived\"].astype(bool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dad3a00",
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert using pandas dtypes\n",
        "pd.Categorical(df[\"Embarked\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5fc3bd7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert with errors='ignore' to avoid exceptions\n",
        "df[\"Age\"].astype(int, errors=\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15d141d1",
      "metadata": {},
      "source": [
        "### <a id='toc3_4_2_'></a>[Handling Mixed Types](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d437c9de",
      "metadata": {},
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cab2451f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert argument to a numeric type\n",
        "pd.to_numeric(df['Sex'], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "749acea7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# detect non-numeric entries\n",
        "df['Age'][~df['Age'].apply(lambda x: isinstance(x, (int, float)))]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e588d8d6",
      "metadata": {},
      "source": [
        "### <a id='toc3_4_3_'></a>[Working with Categorical Data](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c124ee40",
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert a column to categorical\n",
        "categorical = pd.Categorical(df['Pclass'], ordered=True)\n",
        "categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a695bc18",
      "metadata": {},
      "outputs": [],
      "source": [
        "# check categories\n",
        "categorical.categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "084ac0de",
      "metadata": {},
      "outputs": [],
      "source": [
        "# reorder categories\n",
        "categorical.reorder_categories([1, 2, 3], ordered=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2f4065b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# rename categories\n",
        "categorical.rename_categories({1: \"1st\", 2: \"2nd\", 3: \"3rd\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91fed02d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# add a new category\n",
        "categorical.add_categories(['Unknown'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d674386",
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove unused categories\n",
        "categorical.remove_unused_categories()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2b9332c",
      "metadata": {},
      "source": [
        "### <a id='toc3_4_4_'></a>[Optimizing Memory with Categoricals](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6050d081",
      "metadata": {},
      "outputs": [],
      "source": [
        "# check memory usage before conversion\n",
        "print(df['Embarked'].memory_usage(deep=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e638406",
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert object column to categorical\n",
        "categorical_embarked = df['Embarked'].astype('category')\n",
        "\n",
        "# check memory usage before conversion\n",
        "print(categorical_embarked.memory_usage(deep=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f710c1a",
      "metadata": {},
      "source": [
        "## <a id='toc3_5_'></a>[Renaming Columns and Indexes](#toc0_)\n",
        "\n",
        "- Renaming columns and indexes is an important part of **data cleaning**, helping make your dataset more **readable**, **consistent**, and **analysis-friendly**.\n",
        "- While Pandas allows you to rename during creation, real-world datasets often require renaming after loading or merging.\n",
        "\n",
        "‚úçÔ∏è **Key Concepts**\n",
        "\n",
        "- **Rename columns:** Use `.rename(columns={old_name: new_name})` to rename one or multiple columns.\n",
        "- **Rename index:** Use `.rename(index={old_index: new_index})` to rename specific row labels.\n",
        "- **Rename index levels:** For MultiIndex, you can rename **levels** with `.rename_axis()`.\n",
        "- **In-place modification:** Pass `inplace=True` to modify the DataFrame without creating a copy.\n",
        "- **Other transformations:** Add prefixes or suffixes with `.add_prefix()` and `.add_suffix()` for consistent naming conventions.\n",
        "\n",
        "üí° **Best Practices:**\n",
        "- Use **meaningful, descriptive names** for columns and indexes.\n",
        "- Keep names **short but informative** for better readability.\n",
        "- Avoid spaces or special characters when possible ‚Äî consider using underscores.\n",
        "- Standardize capitalization (e.g., all lowercase) for consistency.\n",
        "\n",
        "üìù **Docs**:\n",
        "- `DataFrame.rename()`: [pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html)\n",
        "- `DataFrame.rename_axis()`: [pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename_axis.html](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename_axis.html)\n",
        "- `DataFrame.add_prefix()`: [pandas.pydata.org/docs/reference/api/pandas.DataFrame.add_prefix.html](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add_prefix.html)\n",
        "- `DataFrame.add_suffix()`: [pandas.pydata.org/docs/reference/api/pandas.DataFrame.add_suffix.html](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add_suffix.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c38a4451",
      "metadata": {},
      "source": [
        "### <a id='toc3_5_1_'></a>[Renaming Columns](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d93e0a83",
      "metadata": {},
      "outputs": [],
      "source": [
        "# rename a single column\n",
        "df.rename(columns={'Pclass':'PassengerClass'}, inplace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ffe6e67",
      "metadata": {},
      "outputs": [],
      "source": [
        "# rename multiple columns\n",
        "df.rename(columns={'Name':'FullName', 'Age':'PassengerAge', 'Fare':'TicketFare'}, inplace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fc56a01",
      "metadata": {},
      "outputs": [],
      "source": [
        "# using a function to rename columns\n",
        "df.rename(columns=str.lower, inplace=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57d03649",
      "metadata": {},
      "source": [
        "### <a id='toc3_5_2_'></a>[Renaming Index or Index Levels](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "658c8119",
      "metadata": {},
      "outputs": [],
      "source": [
        "# rename index labels\n",
        "df.rename(index={0:'first_row', 1:'second_row'}, inplace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08223b05",
      "metadata": {},
      "outputs": [],
      "source": [
        "# rename all index labels using a function\n",
        "df.rename(index=lambda x: f'Row_{x}', inplace=False)"
      ]
    }
  ],
  "metadata": {
    "author_email": "AmirhosseinHeydari78@gmail.com",
    "author_github": "https://github.com/mr-pylin",
    "author_name": "Amirhossein Heydari",
    "kernelspec": {
      "display_name": "pandas-workshop (3.13.7)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "origin_repo": "https://github.com/mr-pylin/pandas-workshop"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
